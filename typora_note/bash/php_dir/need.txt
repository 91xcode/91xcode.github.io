春节

es各个版本的变化 以及实际操作


面试题准备 涉及

1.缓存 问题与方案(redis)
	缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级、hotKey、bigKey、DB和缓存一致性问题



	雪崩：缓存在同一时间大量键过期失效，接下来一大波请求全落到数据库中导致连接异常 

	解决办法 
	1.在过期时间上加一个随机时间长度，避免集中过期；
	2.缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存。


	public object GetProductListNew()
        {
            const int cacheTime = 30;
            const string cacheKey = "product_list";
            //缓存标记。
            const string cacheSign = cacheKey + "_sign";
            
            var sign = CacheHelper.Get(cacheSign);
            //获取缓存值
            var cacheValue = CacheHelper.Get(cacheKey);
            if (sign != null)
            {
                return cacheValue; //未过期，直接返回。
            }
            else
            {
                CacheHelper.Add(cacheSign, "1", cacheTime);
                ThreadPool.QueueUserWorkItem((arg) =>
                {
                    cacheValue = GetProductListFromDB(); //这里一般是 sql查询数据。
                    CacheHelper.Add(cacheKey, cacheValue, cacheTime*2); //日期设缓存时间的2倍，用于脏读。                
                });
                
                return cacheValue;
            }
        }

	穿透：恶意用户模拟请求缓存中不存在的数据，全部请求到数据库中导致连接异常  

	解决办法：如果查询数据库也为空，直接设置一个默认值存放到缓存，但它的过期时间会很短，最长不超过五分钟，这样第二次到缓冲中获取就有值了，而不会继续访问数据库

	public object GetProductListNew()
        {
            const int cacheTime = 30;
            const string cacheKey = "product_list";

            var cacheValue = CacheHelper.Get(cacheKey);
            if (cacheValue != null)
                return cacheValue;
                
            cacheValue = CacheHelper.Get(cacheKey);
            if (cacheValue != null)
            {
                return cacheValue;
            }
            else
            {
                cacheValue = GetProductListFromDB(); //数据库查询不到，为空。
                
                if (cacheValue == null)
                {
                    cacheValue = string.Empty; //如果发现为空，设置个默认值，也缓存起来。                
                }
                CacheHelper.Add(cacheKey, cacheValue, cacheTime);
                
                return cacheValue;
            }
        }


	缓存预热

　　缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。

　　解决思路：

　　　　1，直接写个缓存刷新页面，上线时手工操作下。

　　　　2，数据量不大，可以在WEB系统启动的时候加载。

　　　　3，定时刷新缓存，

	缓存更新

	　　缓存淘汰的策略有两种：

	　　　　(1) 定时去清理过期的缓存。

	　　　　(2)当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 

	　　两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。1. 预估失效时间 2. 版本号（必须单调递增，时间戳是最好的选择）3. 提供手动清理缓存的接口。



	缓存降级

	当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

	降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

	在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

	（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；

	（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；

	（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；

	（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。


	hotKey

	热点 key，指的是在一段时间内，该 key 的访问量远远高于其他的 redis key， 导致大部分的访问流量在经过 proxy 分片之后，都集中访问到某一个 redis 实例上

	hot key 之所以是 hot key，是因为它只有一个key，落地到一个实例上


	利用分片算法的特性，对key进行打散处理


	给hot key加上前缀或者后缀，把一个hotkey 的数量变成 redis 实例个数N的倍数M，从而由访问一个 redis key 变成访问 N * M 个redis key。 N*M 个 redis key 经过分片分布到不同的实例上，将访问量均摊到所有实例。

	代码如下：


	//redis 实例数
	const M = 16

	//redis 实例数倍数（按需设计，2^n倍，n一般为1到4的整数）
	const N = 2

	func main() {
	//获取 redis 实例
	    c, err := redis.Dial("tcp", "127.0.0.1:6379")
	    if err != nil {
	        fmt.Println("Connect to redis error", err)
	        return
	    }
	    defer c.Close()

	    hotKey := "hotKey:abc"
	    //随机数
	    randNum := GenerateRangeNum(1, N*M)
	    //得到对 hot key 进行打散的 key
	    tmpHotKey := hotKey + "_" + strconv.Itoa(randNum)

	    //hot key 过期时间
	    expireTime := 50

	    //过期时间平缓化的一个时间随机值
	    randExpireTime := GenerateRangeNum(0, 5)

	    data, err := redis.String(c.Do("GET", tmpHotKey))
	    if err != nil {
	        data, err = redis.String(c.Do("GET", hotKey))
	        if err != nil {
	            data = GetDataFromDb()
	            c.Do("SET", "hotKey", data, expireTime)
	            c.Do("SET", tmpHotKey, data, expireTime + randExpireTime)
	        } else {
	            c.Do("SET", tmpHotKey, data, expireTime + randExpireTime)
	        }
	    }
	}


	另外还有一件事值得一提，默认情况下，我们在生成 tmp key的时候，会把随机数作为 hot key 的后缀，这样符合redis的命名空间，方便 key 的收归和管理。但是存在一种极端的情况，就是hot key的长度很长，这个时候随机数不能作为后缀添加，原因是 Twemproxy 的分片算法在计算过程中，越靠前的字符权重越大，考后的字符权重则越小。也就是说对于key名，前面的字符差异越大，算出来的分片值差异也越大，更有可能分配到不同的实例（具体算法这里不展开讲）。所以，对于很长 key 名的 hot key，要对随机数的放入做谨慎处理，比如放在在最后一个命令空间的最前面（eg：由原来的 space1:space2:space3_rand 改成 space1:space2:rand_space3）



	bigkey 造成集群数据量倾斜

	big key ，即数据量大的 key ，由于其数据大小远大于其他key，导致经过分片之后，某个具体存储这个 big key 的实例内存使用量远大于其他实例，造成，内存不足，拖累整个集群的使用。big key 在不同业务上，通常体现为不同的数据，比如： 1. 论坛中的大型持久盖楼活动； 2. 聊天室系统中热门聊天室的消息列表； ……

	解决方案

	对 big key 进行拆分
	对 big key 存储的数据 （big value）进行拆分，变成value1，value2… valueN,


	如何发现 hot key，big key

	1. 事前-预判

	在业务开发阶段，就要对可能变成 hot key ，big key 的数据进行判断，提前处理，这需要的是对产品业务的理解，对运营节奏的把握，对数据设计的经验。

	2.事中-监控和自动处理

	监控

	- 在应用程序端，对每次请求 redis 的操作进行收集上报;不推荐，但是在运维资源缺少的场景下可以考虑。开发可以绕过运维搞定）；在proxy层，对每一个 redis 请求进行收集上报;（推荐，影响最少，也最直接）；对 redis 实例使用monitor命令统计热点key（不推荐，高并发条件下会有造成redis 内存爆掉的隐患）；机器层面，Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。如果站在机器的角度，可以通过对机器上所有Redis端口的TCP数据包进行抓取完成热点key的统计（不推荐，每台机器上的基本组件已经很多了，别再添乱了）；

	自动处理

	通过监控之后，程序可以获取 big key 和 hot key，再报警的同时，程序对 big key 和 hot key 进行自动处理。或者通知程序猿利用一定的工具进行定制化处理（在程序中对特定的key 执行前面提到的解决方案）

	3.事后

	尽量还是不要事后了吧，都是血和泪的教训，不展开讲


	DB和缓存一致性问题


网络io模型 5种


	IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程
	I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。



	select  系统调用select()方法来监视多个文件描述符的数组，当select()有返回值,该数组中的文件描述符就会被内核修改标志位,使得进程获得这些文件描述符 进行后续的读写操作
	单个进程能够监视的文件描述符的最大数量为1024个

	select()维护的存储大量文件描述符的数据结构 会随着文件描述符数量的增加，其复制的开销也会线性的增长


	poll 同select没有本质区别 解决了单个进程能够监视文件描述符的最大数量

	poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。

	另外，select()和poll()将就绪的文件描述符告诉进程后，如果进程没有对其进行IO操作，那么下次调用select()和poll()的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为水平触发（Level Triggered）

	epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。

	epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。

	另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。


	mmap技术：内核到用户空间，采用共享内存方式传递消息



	水平触发LT（Level Trigger）
	边缘触发ET（Edge Trigger）

	LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误


	epoll是Linux下多路复用IO接口select/poll的增强版本。
　　它能显著减少程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它不会复用文件描述符集合来传递结果而迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合。
　　另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。
　　epoll除了提供select/poll 那种IO事件的电平触发（Level Triggered）外，还提供了边沿触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。





2.消息队列


	1.在何种场景下使用了消息中间件？

	2.为什么要在系统里引入消息中间件？

	3.如何实现幂等？


	消息队列如何保证幂等性？

	主要是看你对消息队列数据重复消费的问题

	问题解决：

	幂等性：一个请求，不管重复来多少次，结果是不会改变的。

	每个消息都会有唯一的消息 id。 1）、先查再保存 每次保存数据的时候，都先查一下，如果数据存在了那么就不保存。这个情况是并发不高的情况。

	2）、业务表添加约束条件 如果你的数据库将来都不会分库分表，那么可以在业务表字段加上唯一约束条件（UNIQUE），这样相同的数据就不会保存为多份。

	3）、添加消息表 再数据库里面，添加一张消息消费记录表，表字段加上唯一约束条件（UNIQUE），消费完之后就往表里插入一条数据。因为加了唯一约束条件，第二次保存的时候，mysql 就会报错，就插入不进去；通过数据库可以限制重复消费。

	4）、使用 redis 如果你的系统是分布式的，又做了分库分表，那么可以使用 redis 来做记录，把消息 id 存在 redis 里，下次再有重复消息 id 在消费的时候，如果发现 redis 里面有了就不能进行消费。

	5）、高并发下 如果你的系统并发很高，那么可以使用 redis 或者 zookeeper 的分布式对消息 id 加锁，然后使用上面的几个方法进行幂等性控制。



	redis

		redis快的原因
			redis单进程 单线程 基于内存 多路 I/O 复用模型


			多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量



		数据持久化、复制、key淘汰策略、主从,哨兵,集群区别


			数据持久化 rdb和aof方式

			rdb是redis默认的持久化方案，在指定的时间间隔内，执行指定次数的写操作，会将内存中的数据写道磁盘中，则在指定的目录下生成一个.rdb文件.redis重启会通过夹在.rdb文件恢复数据

			触发条件 手动触发和自动触发

			手动触发 手动执行save或者bgsave命令都可以生成rdb文件
			save命令会阻塞redis进程，直到rdb文件创建完毕为止，redis服务器进程在阻塞期间，服务器不能处理任何命令请求
			bgsave命令会创建一个子进程，子进程负责创建rdb文件，父进程继续处理请求

			自动触发 最常见的情况是在配置文件中通过save m n 指定当m秒内发生n次变化时，会触发bgsave

			save m n 的实现原理 是通过serverCron函数、dirty计数器、lastsave时间戳来实现的

			对于每个save m n 需要同时满足  当前时间－lastsave >m;dirty >=n

			其它自动触发情况： 
			1.主从复制场景下 如果从节点执行全量复制操作，则主节点会执行bgsave命令 并将rdb文件发给从节点
			2.执行shutdown命令 自动执行rdb持久化


			aof 将redis执行的每次写命令记录到单独的日志文件中，当redis重启是优先执行aof文件中的命令来恢复数据

			开启aof appendonly yes
			aof 执行过程  将redis中的命令追加到缓冲区aof_buf；根据不同的同步策略将aof_buf中的内容同步到硬盘；定期重写aof文件达到压缩的目的


			Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数，说明如下：
			为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此系统同时提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性



			redis提供多种aof_buf数据同步到文件的策略

			always  : 命令写到aof_buf之后立即调用系统的fsync操作同步到aof文件，fsync完成之后线程返回

			no: 命令写到aof_buf之后调用系统的write操作，不对aof文件作fsync同步，同步由操作系统复杂，通常同步周期为30s。这种情况在未同步之前操作系统会将数据暂存在一个内存缓冲区里，如果机器故障，内存缓冲区的数据可能会丢失

			erverysec: 命令写到aof_buf后调用系统fwrite,write完成后线程返回，fsync同步文件操作由专门的线程每秒调用一次


			aof文件重写  把redis进程内的数据转换成写命令，同步到新的aof文件 不会对旧的aof文件进行任何的读写操作

			aof文件重写触发条件：手动和自动

			手动触发：直接调用bgrewriteaof命令 fork子进程进行具体的工作，只有在fork时阻塞
			自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-precentage



			fork阻塞：CPU的阻塞
			在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：

			当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长；
			当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；
			以及持久化过程中的fork操作，下面详细说明





		数据复制(Replication) 主从同步


			1.slave服务器连接master服务器，并且发送rsync命令请求同步

			slave服务器通过syncWithMaster()函数连接master服务器，并且发送rsync命令请求同步，接着打开.rdb文件用于存储master服务器发送过来的rdb文件,创建读rdb的io事件

			2.master服务器备份数据库数据到rdb文件

			当slave服务器发送rsync命令道master服务器，master服务器会调用syncCommand()函数进行同步，同步的第一步是将数据库中的数据备份到rdb文件中，存储完毕之后调用updateSlaveWaitingBgSave()函数发送rdb文件给所有的slave服务器

			当slave服务器接受rdb文件完毕之后，会清空原来数据库的数据，然后将rdb文件的数据导入到数据库中


			增量同步

			当master服务器上有数据增减的时候，调用replicationFeedSlaves()函数把用户执行的命令发送到所有的slave服务器，让slave服务器执行，达到同步数据的效果




		

		数据淘汰策略

			Redis有三种删除key的时机，它们对应不同的淘汰策略： 

			当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key。
			由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key。
			当前已用内存超过maxmemory限定时，触发主动清理策略。



			1、惰性删除：程序在取出键时才判断它是否过期，过期才删除，这个方法对cpu时间友好，对内存不友好。 
			2、定期删除：每隔一定时间执行一次删除过期键的操作，并限制每次删除操作的执行时长和频率，是一种折中。
			3. 主动清理：内存超过maxmemory限定，触发主动清理策略

			定期主动淘汰策略 


			过期数据清理算法

			Redis过期Key清理的机制对清理的频率和最大时间都有限制，在尽量不影响正常服务的情况下，进行过期Key的清理，以达到长时间服务的性能最优.

			Redis会周期性的随机测试一批设置了过期时间的key并进行处理。测试到的已过期的key将被删除。具体的算法如下:

		    Redis配置项hz定义了serverCron任务的执行周期，默认为10，即CPU空闲时每秒执行10次;
		    每次过期key清理的时间不超过CPU时间的25%，即若hz=1，则一次清理时间最大为250ms，若hz=10，则一次清理时间最大为25ms;
		    清理时依次遍历所有的db;
		    从db中随机取20个key，判断是否过期，若过期，则逐出;
		    若有5个以上key过期，则重复步骤4，否则遍历下一个db;
		    在清理过程中，若达到了25%CPU时间，退出清理过程;

			这是一个基于概率的简单算法，基本的假设是抽出的样本能够代表整个key空间，redis持续清理过期的数据直至将要过期的key的百分比降到了25%以下。这也意味着在长期来看任何给定的时刻已经过期但仍占据着内存空间的key的量最多为每秒的写操作量除以4.

			由于算法采用的随机取key判断是否过期的方式，故几乎不可能清理完所有的过期Key;
			调高hz参数可以提升清理的频率，过期key可以更及时的被删除，但hz太高会增加CPU时间的消耗;



			内存超过maxmemory限定，redis主动清理策略
					volatile-lru:从已设置过期的数据集中挑选最近最少使用的淘汰
					volatile-ttr:从已设置过期的数据集中挑选将要过期的数据淘汰
					volatile-random:从已设置过期的数据集中任意挑选数据淘汰
					allkeys-lru:从数据集中挑选最近最少使用的数据淘汰
					allkeys-random:从数据集中任意挑选数据淘汰
					noenviction:禁止淘汰数据
					redis淘汰数据时还会同步到aof中、从机


		主从,哨兵,集群区别

		主从  读写分离、数据备份

		哨兵  高可用(HA)，主挂了哨兵可以切换

		集群  单实例能力有限，搞多个分散压力


		


		Redis的内存用完了会发生什么？

		如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以将Redis当缓存来使用配置淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容


		Redis常见性能问题和解决方案？

		(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件

		(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次

		(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内

		(4) 尽量避免在压力很大的主库上增加从库

		(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...

		这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。


		Redis集群方案应该怎么做？都有哪些方案？

		1.twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy。使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。

		2.codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。

		3.redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。

		4.在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

	kafka
		Kafka原理  使用过程中遇到的问题和解决办法

		场景：日志收集系统和消息系统

		优势：
		以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。
		高吞吐率，即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。
		支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。
		同时支持离线数据处理和实时数据处理。






		新版本（0.9+）的Kafka将consumer group的消费偏移量保存在一个特殊的topic里，在此之前的版本中都是保存在zookeeper里


		kafka用zookeeper实现的服务类型。

			1，配置管理

			Topic的配置之所以能动态更新就是基于zookeeper做了一个动态全局配置管理。

			2，负载均衡

			基于zookeeper的消费者，实现了该特性，动态的感知分区变动，将负载使用既定策略分不到消费者身上。

			3，命名服务

			Broker将advertised.port和advertised.host.name，这两个配置发布到zookeeper上的zookeeper的节点上/brokers/ids/BrokerId(broker.id),这个是供生产者，消费者，其它Broker跟其建立连接用的。

			4，分布式通知

			比如分区增加，topic变动，Broker上线下线等均是基于zookeeper来实现的分布式通知。

			5，集群管理和master选举

			我们可以在通过命令行，对kafka集群上的topic partition分布，进行迁移管理，也可以对partition leader选举进行干预。

			Master选举，要说有也是违反常规，常规的master选举，是基于临时顺序节点来实现的，序列号最小的作为master。而kafka的Controller的选举是基于临时节点来实现的，临时节点创建成功的成为Controller，更像一个独占锁服务。

			6，分布式锁

			独占锁，用于Controller的选举。


		Kafka文件的存储机制

			同一个topic下有多个不同的partition，每个partition为一个目录，partition命名的规则是topic的名称加上一个序号，序号从0开始。每一个partition目录下的文件被平均切割成大小相等（默认一个文件是500兆，可以手动去设置）的数据文件，
			每一个数据文件都被称为一个段（segment file），但每个段消息数量不一定相等，这种特性能够使得老的segment可以被快速清除。
			默认保留7天的数据。

			另外每个partition只需要支持顺序读写就可以了，partition中的每一个segment端的生命周期是由我们在配置文件中指定的一个参数觉得的。
			比如它在默认情况下，每满500兆就会创建新的segment段（segment file），每满7天就会清理之前的数据。

		如何保证消息消费的有序性呢？

			针对一个topic里面的数据，只能做到partition内部有序，不能做到全局有序。特别是加入消费者的场景后，如何保证消费者的消费的消息的全局有序性，只有在一种情况下才能保证消费的消息的全局有序性，那就是只有一个partition


		Segment file是什么？

			生产者生产的消息按照一定的分组策略被发送到broker中partition中的时候，这些消息如果在内存中放不下了，就会放在文件中，
			partition在磁盘上就是一个目录，该目录名是topic的名称加上一个序号，在这个partition目录下，有两类文件，一类是以log为后缀的文件，
			一类是以index为后缀的文件，每一个log文件和一个index文件相对应，这一对文件就是一个segment file，也就是一个段。
			其中的log文件就是数据文件，里面存放的就是消息，而index文件是索引文件，索引文件记录了元数据信息。



		Kafka消息保证不丢失和重复消费问题

		在如下情况会有消息丢失

			使用同步模式的时候，在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。
			使用异步模式的时候，当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。


		在数据生产时避免数据丢失的方法：
			只要能避免上述两种情况，那么就可以保证消息不会被丢失。
			就是说在同步模式的时候，确认机制设置为-1，也就是让消息写入leader和所有的副本。
			还有，在异步模式下，如果消息发出去了，但还没有收到确认的时候，缓冲池满了，在配置文件中设置成不限制阻塞超时的时间，也就说让生产端一直阻塞，这样也能保证数据不会丢失。


		数据重复消费的原因

			kafka的consumer消费数据时首先会从broker里读取一批消息数据进行处理，处理完成后再提交offset。而我们项目中的consumer消费能力比较低，导致取出的一批数据在session.timeout.ms时间内没有处理完成，自动提交offset失败，然后kafka会重新分配partition给消费者，消费者又重新消费之前的一批数据，又出现了消费超时，所以会造成死循环，一直消费相同的数据

			数据重复消费的情况，如果处理？
			（1）去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过；
			（2）自己业务逻辑实现，例如不管逻辑代码执行多少次，只要是同一个编号处理，得到的结果都是一样的，例如更新订单状态，只要是同一个订单号，就算重复消费，执行了多个update，最终数据库还是一样的结果
			（3）不管：大数据场景中，报表系统或者日志信息丢失几条都无所谓，不会影响最终的统计分析结果。


		消息队列的应用场景、消息的重发补偿解决思路、消息的幂等性解决思路、消息的堆积解决思路、消息的有序性保证思路


垃圾回收
https://segmentfault.com/a/1190000018161588
https://testerhome.com/topics/16556
https://juejin.im/post/5c7b785af265da2d8c7de5f1
https://studygolang.com/articles/21688

什么才是垃圾
在我们看来，一个对象以后都不用了，就是垃圾。
在程序看来，一个对象没有被引用了，就是垃圾。

		垃圾回收常见的方法
		引用计数（reference counting）

		引用计数通过在对象上增加自己被引用的次数，被其他对象引用时加1，引用自己的对象被回收时减1，引用数为0的对象即为可以被回收的对象。这种算法在内存比较紧张和实时性比较高的系统中使用的比较广泛，如ios cocoa框架，php，python等。

		优点：

		1、方式简单，回收速度快。

		缺点：

		1、需要额外的空间存放计数。

		2、无法处理循环引用（如a.b=b;b.a=a这种情况）。

		3、频繁更新引用计数降低了性能。

		标记-清除（mark and sweep）

		该方法分为两步，标记从根变量开始迭代得遍历所有被引用的对象，对能够通过应用遍历访问到的对象都进行标记为“被引用”；标记完成后进行清除操作，对没有标记过的内存进行回收（回收同时可能伴有碎片整理操作）。这种方法解决了引用计数的不足，但是也有比较明显的问题：每次启动垃圾回收都会暂停当前所有的正常代码执行，回收是系统响应能力大大降低！当然后续也出现了很多mark&sweep算法的变种（如三色标记法）优化了这个问题。

		复制收集

		复制收集的方式只需要对对象进行一次扫描。准备一个「新的空间」，从根开始，对对象进行扫，如果存在对这个对象的引用，就把它复制到「新空间中」。一次扫描结束之后，所有存在于「新空间」的对象就是所有的非垃圾对象。

		这两种方式各有千秋，标记清除的方式节省内存但是两次扫描需要更多的时间，对于垃圾比例较小的情况占优势。复制收集更快速但是需要额外开辟一块用来复制的内存，对垃圾比例较大的情况占优势。特别的，复制收集有「局部性」的优点。

		在复制收集的过程中，会按照对象被引用的顺序将对象复制到新空间中。于是，关系较近的对象被放在距离较近的内存空间的可能性会提高，这叫做局部性。局部性高的情况下，内存缓存会更有效地运作，程序的性能会提高。

		对于标记清除，有一种标记-压缩算法的衍生算法：

		对于压缩阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的。

		分代收集（generation）

		分代回收是一种以空间换时间的操作方式，Python将内存根据对象的存活时间划分为不同的集合，每个集合称为一个代，Python将内存分为了3“代”，分别为年轻代（第0代）、中年代（第1代）、老年代（第2代），他们对应的是3个链表，它们的垃圾收集频率与对象的存活时间的增大而减小。
		新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到中年代去，依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。
		同时，分代回收是建立在标记清除技术基础之上。分代回收同样作为Python的辅助垃圾收集技术处理那些容器对象

		这种方式存在一个问题：如果在某个新生代的对象中，存在「老生代」的对象对它的引用，它就不是垃圾了，那么怎么制止「小回收」对其回收呢？这里用到了一中叫做写屏障的方式。

		程序对所有涉及修改对象内容的地方进行保护，被称为「写屏障」（Write Barrier）。写屏障不仅用于分代收集，也用于其他GC算法中。

		在此算法的表现是，用一个记录集来记录从新生代到老生代的引用。如果有两个对象A和B，当对A的对象内容进行修改并加入B的引用时，如果①A是「老生代」②B是「新生代」。则将这个引用加入到记录集中。「小回收」的时候，因为记录集中有对B的引用，所以B不再是垃圾。

		三色标记算法
		三色标记算法是对标记阶段的改进，原理如下：

		起初所有对象都是白色。
		从根出发扫描所有可达对象，标记为灰色，放入待处理队列。
		从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。
		重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。



	MQ系列
	    rabbitmq
	    Rocketmq



	锁

	表锁 行锁 乐观锁 悲观锁的特点和区别

	分布式锁

		分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁

		可靠性

		首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：

	    互斥性。在任意时刻，只有一个客户端能持有锁。
	    不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
	    具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
	    解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。




 3.储存(mysql;s3;es)

	mysql


		mysql索引类别


		索引是一种数据结构,可以是BTREE,RTREE,或者HASH结构.
		BTREE适合用于查找某范围内的数据,可以很快的从当前数据找到下条数据.
		RTREE常用于查询比较接近的数据.
		HASH结构则适用于随机访问的场合,查找每条数据的时间几乎相同.

		从物理存储角度

			1、聚集索引（clustered index）

			2、非聚集索引（non-clustered index）






			聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个 ！ 

			聚集索引存储记录是物理上连续存在，而非聚集索引是逻辑上的连续，物理存储并不连续 ！


			在建立主键的时候可以声明为CLUETERED(聚集)或NONCLUETERED(非聚集)


			主键 默认是加了唯一约束的聚集索引，但是也可以在主键创建时，指定为唯一约束的非聚集索引，因此主键仅仅是默认加了唯一约束的聚集索引，不能说主键就是加了唯一约束的聚集索引   SQLServer默认主键就是聚焦索引




			聚集索引只能是一个,其他的单独索引及联合索引可以理解为非聚集索引.



			主键一唯一索引的区别：

			     1 一个表的主键只能有一个，而唯一索引可以建多个。
			     2 主键可以作为其它表的外键。
			     3 主键不可为null，唯一索引可以为null。



			聚集索引的叶节点就是数据节点，而非聚集索引的叶节点仍然是索引节点，只不过其包含一个指向对应数据块的指针

			聚集索引和非聚集索引的索引走向：

			首先通过innodb的查询优化器判断你的请求是否是聚集索引请求。

			如果是< 聚集索引 >，那么会在 innodb_buffer_pool里找到第一层B+tree,  如果找到区间，那么继续找第二层B+tree， 最终拿到row 数据 。

			如果是< 非聚集索引 >，那么就是找到相关的非聚集索引了，通过索引字段查到对应的主键，然后拿着主键去拿聚集索引拿数据


			B+树不是一个二叉树。
			B+树并不能直接找到具体的行，B+树索引只能找到数据行所在的页，然后数据库通过把页读入内存，再在内存中进行查找



		什么是覆盖索引

			查询列要被所建的索引覆盖



		

		b+树和b树的区别


			1. B+树中只有叶子节点会带有指向记录的指针（ROWID），而B树则每个节点都存有索引和数据，在内部节点出现的索引项不会再出现在叶子节点中。

			2. B+树中所有叶子节点都是通过指针连接在一起，而B树不会。

			 

			B+树的优点：

			1. 非叶子节点不会带上ROWID，这样，一个块中可以容纳更多的索引项，一是可以降低树的高度。二是一个内部节点可以定位更多的叶子节点。

			2. 叶子节点之间通过指针来连接，范围扫描将十分简单，而对于B树来说，则需要在叶子节点和内部节点不停的往返移动。

			 

			B树的优点：

			对于在内部节点的数据，可直接得到，不必根据叶子节点来定位。

		为什么选用自增量作为主键索引

		mysql如何优化查询



		数据类型的区别
		索引及其原理
		数据库主从同步原理以及错误和解决办法
		数据库集群
		数据库连接数不够 紧急处理办法
		mysql5.5和5.6的区别
		大表添加索引和增加字段的影响和处理办法




		分页：
		select a.tid,a.return_date from  t1 a 
		inner join 
		(select tid from t1 order by  inventory_id limit 800000,10) b on a.tid=b.tid;

		alter table t1 add index idx_inid(inventory_id),drop index liu;


	s3
		aws上提供的s3服务，阿里云和腾讯云分别是什么 怎么使用 有哪些注意事项

	es 
		5.3和5.4和6.x的区别
		集群原理和安装的主意事项
		在语言中的使用(PHP Python)

		遇到的坑(比如分页1000页问题；保存日志类索引的模版设置；如何因为盘空间不够进行扩容；如何不停服务在线和离线迁移数据；如何无缝reindex)
		常规日志收集服务elk  能处理大的量级的数据 瓶颈在那





4.Web服务器
	Nginx
		系统容错能力 主要集中在重试机制，高可用，超时配置，服务降级，动态健康检查剔除机制等


5.PHP

	PHP的垃圾回收原理 
	排序 
	数组在PHP底层的实现过程 
	PHP的写时复制机制（Copy-On-Write)
	不同版本的区别 
	502和504区别
	一致性hash
	闭包匿名函数



6.Linux
	常规操作 常用命令 查看端口

7.shell
	常规操作
		处理accesslog
		统计qps
		多进程控制进程并发执行
		删除过期文件和目录


8.前端 bootstrap vue echarts

9.大数据处理方式方法 Hadoop hive hbase hdfs sqool


10.分布式的配置 以及host发现 zk consoul ect

11.通用文件性上报架构方案  通用多产品后台基础服务  多产品的用户中心 开放平台架构



一次I/O完成的步骤

当进程发起系统调用时候,这个系统调用就进入内核模式, 然后开始I/O操作
I/O操作分为俩个步骤: 

 1) 磁盘把数据装载进内核的内存空间

 2) 内核的内存空间的数据copy到用户的内存空间中(此过程才是真正I/O发生的地方) 





 nginx为什么比Apache支持高并发




 redis淘汰策略

1.no-evication 不会删除任何数据 拒绝所有写操作 并且返回客户端错误信息  error oom 此时redis只响应读操作


2.allkeys-random  从数据集中选择任意数据进行淘汰  


3.allkeys-lru   从数据集中选择最近最少使用的数据进行淘汰

4.volatile-lru  从已经设置过期时间的数据集中挑选最近最少使用的数据进行淘汰

5.volatile-ttl  从已经设置过期时间的数据集中选择即将要过期的数据进行淘汰

6.volatile-random 从已经设置过期时间的数据集中选择任意数据进行淘汰



nginx快

nginx使用的是epoll模型，该模型特点如下：

多进程单线程模型：Nginx

1、无文件描述字大小限制仅与内存大小相关。

2、epoll返回时已经明确的知道哪个socket fd发生了什么事件，不用像select那样再一个个比对。 epoll采用基于事件的就绪通知方式

3、内核到用户空间，采用共享内存方式传递消息。使用mmap加速内核与用户空间的消息传递 epoll是通过内核于用户空间mmap同一块内存实现的

apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程



PHP写时复制（Copy On Write）

写时复制优点：是通过赋值的方式赋值给变量时不会申请新内存来存放新变量所保存的值，而是简单的通过一个计数器来共用内存，只有在其中的一个引用指向变量的值发生变化时才申请新空间来保存值内容以减少对内存的占用。